{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fkh0V-xzloaO8lhoHincG9bcqwHLyzNC","timestamp":1685526770091}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6MBlmTmtXvS","outputId":"55851e0a-5e78-4f2f-a038-582177f70ae3"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["import nltk\n","nltk.download(\"punkt\")\n","nltk.download(\"stopwords\")\n","nltk.download(\"wordnet\")\n","nltk.download(\"averaged_perceptron_tagger\")"]},{"cell_type":"markdown","source":["# Tokenization"],"metadata":{"id":"mqifWtX10SEO"}},{"cell_type":"code","source":["from nltk import word_tokenize, sent_tokenize"],"metadata":{"id":"GqMdfjxg0fCl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus = \"Sachin was the GOAT of the previous generation. Virat is the GOAT of this generation. Shubman will be the GOAT of the next generation\""],"metadata":{"id":"lqQuKfyf0T_h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(word_tokenize(corpus))\n","print(sent_tokenize(corpus))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qygvks1B0lmO","outputId":"61355537-c342-4b3f-8e5a-7e7c29a0ce3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Sachin', 'was', 'the', 'GOAT', 'of', 'the', 'previous', 'generation', '.', 'Virat', 'is', 'the', 'GOAT', 'of', 'this', 'generation', '.', 'Shubman', 'will', 'be', 'the', 'GOAT', 'of', 'the', 'next', 'generation']\n","['Sachin was the GOAT of the previous generation.', 'Virat is the GOAT of this generation.', 'Shubman will be the GOAT of the next generation']\n"]}]},{"cell_type":"markdown","source":["# POS tagging"],"metadata":{"id":"EDWyjOif06Nt"}},{"cell_type":"code","source":["from nltk import pos_tag"],"metadata":{"id":"sjrjZaOt07F8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens = word_tokenize(corpus)\n","print(pos_tag(tokens))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gG_Jm78o0-Ui","outputId":"118898ef-0fef-496c-bbaa-c7c722f8caf0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('Sachin', 'NNP'), ('was', 'VBD'), ('the', 'DT'), ('GOAT', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('previous', 'JJ'), ('generation', 'NN'), ('.', '.'), ('Virat', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('GOAT', 'NNP'), ('of', 'IN'), ('this', 'DT'), ('generation', 'NN'), ('.', '.'), ('Shubman', 'NNP'), ('will', 'MD'), ('be', 'VB'), ('the', 'DT'), ('GOAT', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('next', 'JJ'), ('generation', 'NN')]\n"]}]},{"cell_type":"markdown","source":["# Stop word removal"],"metadata":{"id":"yg1AKO8k1K_i"}},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","stop_words = set(stopwords.words(\"english\"))"],"metadata":{"id":"0jPJ1Lzo1PfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens = word_tokenize(corpus)\n","cleaned_tokens = []\n","for token in tokens:\n","  if (token not in stop_words):\n","    cleaned_tokens.append(token)\n","print(cleaned_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKO5yKaz1aqe","outputId":"ff319b8b-11bb-4506-a69f-b688e4415669"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Sachin', 'GOAT', 'previous', 'generation', '.', 'Virat', 'GOAT', 'generation', '.', 'Shubman', 'GOAT', 'next', 'generation']\n"]}]},{"cell_type":"markdown","source":["# Stemming"],"metadata":{"id":"XoOJBXwg1u70"}},{"cell_type":"code","source":["from nltk.stem import PorterStemmer"],"metadata":{"id":"agRU5bvH1wIo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stemmer = PorterStemmer()"],"metadata":{"id":"XB23t5ni1yZe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stemmed_tokens = []\n","for token in cleaned_tokens:\n","  stemmed = stemmer.stem(token)\n","  stemmed_tokens.append(stemmed)\n","print(stemmed_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0SE0s-010bV","outputId":"8568f843-d275-4d82-d6fc-998d3f01eb3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['sachin', 'goat', 'previou', 'gener', '.', 'virat', 'goat', 'gener', '.', 'shubman', 'goat', 'next', 'gener']\n"]}]},{"cell_type":"markdown","source":["# Lemmatization"],"metadata":{"id":"PehRHjsc2JQa"}},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer"],"metadata":{"id":"XmsB1yGV2KaO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()"],"metadata":{"id":"lv7ul_kL2NkC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lemmatized_tokens = []\n","for token in cleaned_tokens:\n","  lemmatized = lemmatizer.lemmatize(token)\n","  lemmatized_tokens.append(lemmatized)\n","print(lemmatized_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FonvIUEn2UB_","outputId":"2362a60b-3ed6-417d-9ccf-de4b9a4033eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Sachin', 'GOAT', 'previous', 'generation', '.', 'Virat', 'GOAT', 'generation', '.', 'Shubman', 'GOAT', 'next', 'generation']\n"]}]},{"cell_type":"markdown","source":["# TF-IDF"],"metadata":{"id":"BrvioSJb27bT"}},{"cell_type":"code","source":["import pandas as pd\n","\n","from sklearn. feature_extraction.text import TfidfVectorizer"],"metadata":{"id":"qFJSY02YKBRx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["documentA = 'Jupiter is the largest Planet'\n","\n","documentB = 'Mars is the fourth planet from the Sun'"],"metadata":{"id":"BA7sRShPKBOX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bagofwordsA = documentA.split() \n","bagofwordsB = documentB.split()"],"metadata":{"id":"UqaMfH8JKBLZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["uniqueWords = set(bagofwordsA).union(set(bagofwordsB))"],"metadata":{"id":"gd-_lVsIKBIi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numOfWordsA = dict.fromkeys(uniqueWords, 0)\n","for word in bagofwordsA: \n","  numOfWordsA[word] += 1\n","numOfWordsB = dict.fromkeys (uniqueWords, 0)\n","for word in bagofwordsB: \n","  numOfWordsB[word] += 1"],"metadata":{"id":"Kk3RQxEJKBFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def computeTF(wordDict, bagOfWords):\n","  tfDict= {}\n","  bagofwordsCount = len(bagOfWords) \n","  for word, count in wordDict.items():\n","    tfDict[word] = count / float (bagofwordsCount)\n","  return tfDict\n","  tfA = computeTF (numOfWordsA, bagOfWordsA) \n","  tfB = computeTF (numOfWordsB, bagOfWordsB)"],"metadata":{"id":"niZX5jL3KBCw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def computeIDF (documents):\n","  import math\n","  N= len(documents)\n","  idfDict = dict. fromkeys (documents[0].keys(), 0)\n","  for document in documents:\n","    for word, val in document.items():\n","      if val> 0:\n","        idfDict[word] += 1 \n","  for word, val in idfDict.items():\n","    idfDict[word] = math.log(N/ float(val))\n","  return idfDict\n","  idfs = computeIDF ([numOfWordsA, numOfWordsB])\n","  idfs"],"metadata":{"id":"bltuTVRJKA_7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def computeTFIDF (tfBagOfWords, ides):\n","  tfidf = {}\n","  for word, val in tfBagOfWords.items():\n","    tfidf[word] = val * idfs[word] \n","  return tfidf \n","  tfidfA = computeTFIDF(tfA, idfs) \n","  tfidfB = computeTFIDF(tfB, idfs) \n","  df = pd.DataFrame([tfidfA, tfidfB]) \n","  df"],"metadata":{"id":"jpNx3wbMKA80"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_uRlABFTKA6C"},"execution_count":null,"outputs":[]}]}